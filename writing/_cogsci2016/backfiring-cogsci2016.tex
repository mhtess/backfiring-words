% 
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
% \


% to do
% -- consistent names of conditions: listener uncertainty in common ground vs. not
% -----

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{url}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{color}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{lipsum}
\usepackage{epigraph}

\graphicspath{{figures/}}

\def\signed #1{{\leavevmode\unskip\nobreak\hfil\penalty50\hskip2em
  \hbox{}\nobreak\hfil(#1)%
  \parfillskip=0pt \finalhyphendemerits=0 \endgraf}}

\newsavebox\mybox
\newenvironment{aquote}[1]
  {\savebox\mybox{#1}\begin{quote}}
  {\signed{\usebox\mybox}\end{quote}}

 \newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}

\definecolor{Red}{RGB}{255,0,0}
\newcommand{\red}[1]{\textcolor{Red}{#1}}  

\definecolor{Blue}{RGB}{0,0,255}
\newcommand{\blue}[1]{\textcolor{Blue}{#1}}  
\definecolor{Green}{RGB}{10,200,100}
\newcommand{\ndg}[1]{\textcolor{Green}{[ndg: #1]}}  
\newcommand{\mht}[1]{\textcolor{Blue}{[mht: #1]}}  

\title{It goes without saying: The pragmatics of uninformative utterances}

\author{ {\large \bf Michael Henry Tessler*}, {\large \bf Eleanor K. Chestnut*},
{\large \bf Ellen M. Markman}, and {\large \bf Noah D. Goodman}  \\
\{mtessler, ekc, markman, ngoodman\} @stanford.edu \\ 
  Department of Psychology, Stanford University \\
  *Authors contributed equally to this work.}

\begin{document}

\maketitle


\begin{abstract}
%\ndg{abstract is too technical. start with the puzzle of how asserting a proposition can sometimes decrease its plausibility. the use of common ground here is kind of hard to follow.}
The utterance ``Jane went for a hike today" can serve as evidence that Jane likes to go on hikes.  However, ``Jane wore shoes today'' seems to imply the opposite.  In this case, listeners infer that Jane does \emph{not} like to wear shoes (e.g., \cite{Kravtchenko2015}.  Why should some utterances serve as evidence for a given behavior, while others serve as evidence against it?  We present a formal language understanding model that is able to revise information that is common ground when an utterance is uninformative with respect to prior beliefs.  The model predicts that this ``backfiring'' inference relies on shared knowledge between speaker and listener, which we manipulate in Experiment 1, and \emph{a priori} beliefs about the event under discussion, which we manipulate and measure in Experiment 2. 
%In Experiment 1, we show that this inference does not occur when interlocutors are mutually aware of information in common ground, or when a statement is removed from a conversational context.  In Experiment 2, we show that the \emph{existence} and \emph{strength} of this inference depends on the listener's prior  beliefs., which we measure empirically.
% Finally, we present a computational model that predicts these results.
% that when an utterance is redundant with the prior beliefs of the listener (most people wear shoes and shoe-wearing tends to happen everyday), adults will revise information that is in common ground with the speaker (here, that Jane typically wears shoes) so that the utterance becomes informative.  
%Successful communication requires a mutually understood set of beliefs between speaker and listener.
%When common ground is not shared, a listener can use a speaker's utterance in conjunction with conversational principles to infer what was assumed by the speaker.
%Previous work has shown that this inference can have surprising ramifications, including decreasing the belief in the proposition that was asserted by the speaker 
%(e.g. upon hearing, ``John paid the cashier!'', listeners infer that John does not typically pay for his groceries).
% i just think we need an example somewhere in here
%Here, we formalize inferences about common ground using the case when a speaker's utterance refers to something that should already be in common ground.
%The formal pragmatics model makes clear that this kind of utterance will backfire (i.e. imply that the opposite is typically true) when the interlocutors do not share common ground, but not when they do.
% the last sentence is a little hard to read because of many "not"s... but we can worry about that later.
%Language is interpreted in context with respect to some common ground between speaker and listener.
%Common ground can make certain utterances uninformative (e.g. stating something obvious), but is plausibly revised in the face of uninformative utterances.
%In Expt.~1, we verify this prediction using a paradigm that makes the 

\textbf{Keywords:} 
pragmatics; language; common ground; Bayesian model
\end{abstract}


%\begin{quotation}
%\small
%``I am not a crook.'' -- Richard Nixon

%\end{quotation}

%In one of the most infamous moments in U.S. presidential history, Richard Nixon declared to the press corps, "I am not a crook"√¢‚Äö¬¨√Ç¬ù (CITE).  On the surface, this claim argues for Nixon's innocence, as it literally states that he is not a crook.  As several researchers have shown, however, this statement contains a number of pragmatic implications that actually counter its literal, semantic meaning (CITE).  Nixon'√¢‚Äö¬¨√¢‚Äû¬¢s claim, for instance, presupposes that others believed that he was a crook; otherwise, it would not have been an informative statement to make, since most people presumably are not crooks (Grice, 1975).  Thus, if a listener is not aware of the Watergate scandal, or if they have no reason to question Nixon's moral status, they might actually learn from this claim that Nixon was likely corrupt in some way.

In 1974, beleaguered U.S. President Richard Nixon declared to the press corps, ``I am not a crook.''.  
If we were to take Nixon's words on face value, they would seem to imply he is a good guy (That is what the words mean.).
However, the fact that Nixon said this, which----for a president, at least----should go without saying, we take his utterance to imply the opposite.

%% I'd like to avoid technical words (literal, pragmatic) and citations in the first few sentences... Should be something a non-language person can appreciate
%On a literal level, this claim argues for Nixon's innocence.  
%Pragmatically, however, this claim presupposes that someone has accused Nixon of a crime; otherwise, the claim would not be informative (Grice, 1975).  
%Thus, contrary to Nixon's intentions, a listener unaware of the Watergate scandal could actually \emph{learn} from this utterance that Nixon was associated with corruption.

To date, this phenomenon---that utterances can ``backfire" (i.e., decrease a listener's belief in the content being asserted)---is not well understood.  Instead, the standard Bayesian treatment of learning from testimony has stressed fact that we update our beliefs about the world to be  \emph{in accordance} with information expressed through language \red{(cite)}. 
In the social psychological literature, however, two studies have found that \emph{a priori} uninformative newspaper headlines negating negative associations (e.g.,``Bob Talbert not linked with mafia"\footnote{This is uninformative because most people are not in the mafia.})
cause adults to have a more negative impression of the target (i.e., Mr. Talbert) than they would otherwise \cite{Wegner1981}, and can actually cause people to believe the exact opposite of what those headlines claim \cite{Gruenfeld1992}.
% A few studies, however, provide evidence that when utterances are redundant with a listener's prior beliefs, they can imply that the opposite of what is expressed. 
% \citeA{Wegner1981}, for example, demonstrated  despite explicitly denying incriminating information. Similarly, Gruenfeld and Wyer (1992) showed that uninformative newspaper headlines can actually    
 \citeA{Gruenfeld1992}, for example, found that fake headlines such as ``Robert Kennedy was not planning the assassination of Fidel Castro" actually caused adults to more strongly believe that Kennedy \emph{had} been planning to assassinate Castro. 
 Backfiring can also occur in conversation: \citeA{Kravtchenko2015} recently demonstrated that if a speaker says, ``John paid the cashier!" as part of a story about John's trip to a grocery store, adults infer that John does not typically pay cashiers.

Why do claims like the ones above backfire, while others don't? We suggest that this effect depends on the common ground shared between interlocutors, and the conversational principle that utterances should be both relevant and informative (Grice, 1975).  We develop these ideas in the section below.  In short, when an utterance does not appear on the surface to be informative, interlocutors are able to adjust information that is in common ground to \emph{make} the utterance informative (CITE accommodation?).

In this paper, we formalize pragmatic language models wherein speaker and listener either do or do not share common ground about a people's habits (e.g., a student's tendency to turn in her homework on time).
These models make three predictions: (a) Backfiring should occur when common ground is \emph{not} shared between interlocutors; here, the speaker will be interpreted as presupposing information that the listener was not aware of, thereby causing the listener to infer that information; (b) When common ground \emph{is} shared, standard learning from testimony should occur, because the speaker's utterances will be understood as semantically informative for the listener; and (c) The existence and strength of backfiring should vary according to the strength of the prior beliefs that are redundant with the utterance, since greater redundancy would cause utterances to be less informative.  In Experiment 1, we use a two-alternative forced-choice paradigm to  test the predictions (a) \& (b) and conceptually replicate \citeA{Kravtchenko2015}, who demonstrated the basic \emph{backfiring} effect for affirmations in conversation (e.g., ``John paid the cashier").  
In Experiment 2, we harness participants' intuitive theories of event frequencies to construct a more minimal paradigm with a free response format to test the degree to which remarks about a wide range of events (e.g., ``Lewis went for a run today'', ``Lewis went for a hike today.') lead to backfiring (prediction c). 

%The model that displays the backfiring effect (common ground asymmetric) predicts the quantitative degree of backfiring contingent on the prior probability of the event occurring. 
%We test the quantitative predictions of this model in Expt.~2. 

%Why do claims like these backfire, while most of testimony from others does not?
%We suggest that this effect depends on the shared beliefs between interlocutors as well the details of these beliefs in terms of the \emph{a priori} likelihood of the asserted content.
%Communication in general is successful only when interlocutors share common ground \cite{Clark1996}.  
%In this paper, we formalize pragmatic language models wherein speaker and hearer both do not and do not share common ground.
%The pair of models predicts that utterances should backfire when common ground is \emph{not} symmetric between interlocutors, but that when common ground is shared, typical learning from testimony will result.
%In Expt.~1, we conceptually replicate \citeA{Kravtchenko2015}, who first demonstrated the basic \emph{backfiring} effect, and test the novel prediction about common ground made our model family. 
%The model that displays the backfiring effect (common ground asymmetric) predicts the quantitative degree of backfiring contingent on the prior probability of the event occurring. 
%We test the quantitative predictions of this model in Expt.~2. 

%Richard Nixon is a controversial figure.
%If you didn't already know this, you might infer it from his utterance above.
%Why else would he need to declare it, if his crookedness were not in question?


%In one of the most infamous moments in U.S. presidential history, Richard Nixon declared to the press corps, ``I am not a crook" (CITE).  
%
%On the surface, this claim argues for Nixon's innocence, as it literally states that he is not a crook.  As some researchers have argued, however, this statement contains a number of pragmatic implications that actually counter its literal, semantic meaning (CITE).  Nixon's claim, for instance, presupposes that others believed that he \emph{was} a crook; otherwise, it would not have been an informative statement to make, since most people presumably are not crooks (Grice, 1975).  Thus, if a listener (e.g., a student in a history class) is not aware of the Watergate scandal, or if they have no reason to question Nixon's moral status, they might actually \emph{learn} from this claim that Nixon was likely corrupt in some way.
%


	
%A few studies, however, provide preliminary evidence that utterances that are redundant with a listener'√¢‚Äö¬¨√¢‚Äû¬¢s preexisting beliefs do cause listeners to search for ways to make those utterances informative \cite{Yandell1979, Wegner1981, Gruenfeld1992, Kravtchenko2015}.  This process ultimately undermines the utterances' literal meanings.  

%%\citeA{Wegner1981}, for example, demonstrated that newspaper headlines such as "√¢‚Äö¬¨√Ö%‚ÄúBob Talbert is not linked to the Mafia" [CHECK] cause adults to have a more negative impression of Bob than they would otherwise, despite not explicitly asserting any incriminating information--indeed, despite denying incriminating information.  Here, since the default assumption is that people are not typically linked to the mafia, this headline is not immediately informative.  As a result, adults construct a context that \emph{would} make the headline informative, namely, one in which Bob is known to be a bad person.  
%%\citeA{Gruenfeld1992} went even further to show that uninformative newspaper headlines can actually cause people to believe the exact opposite of what those headlines claim.  After reading the headline "√¢‚Äö¬¨√Ö%‚ÄúRobert Kennedy was not planning the assassination of Fidel Castro"√¢‚Äö¬¨√Ç¬ù, for example, which denies a proposition that adults \emph{a priori} should not believe, adults in their study more strongly believed that Robert Kennedy \emph{was} planning to assassinate Fidel Castro.

%The phenomenon that utterances can ``backfire" (i.e. decrease a listener's belief in the content it is asserting) is not well understood. % received little attention in the field.  
%The broad literature on learning from testimony has yet to address this.
%The standard Bayesian treatment would say we update our beliefs about the world to be  \emph{in accordance} with information expressed through language \red{(cite)}.  If a teacher says to a student, ``Nixon served as President of the United States," for instance, then that student will likely incorporate into their world knowledge that Nixon \emph{was}, in fact, President of the United States.  
%A few studies, however, provide preliminary evidence that utterances that are redundant with a listener's prior beliefs can imply that the opposite of what is expressed is typically true, by forcing the listeners to search for ways to make the utterances informative (CITE).  

%A few studies have suggestive evidence that when utterances are redundant with a listener's prior beliefs, they can imply the opposite of what is asserted.
%\citeA{Wegner1981}, for example, demonstrated that newspaper headlines such as ``Bob Talbert not linked with mafia'' cause adults to have a more negative impression of Mr. Talbert than they would otherwise, despite denying incriminating information.  Similarly, \citeA{Gruenfeld1992} showed that uninformative newspaper headlines can actually cause people to believe the exact opposite of what those headlines claim.  
%After reading the headline ``Robert Kennedy was not planning the assassination of Fidel Castro'', for example, adults in their study more strongly believed that Kennedy \emph{was} planning to assassinate Castro.  
%More directly, \citeA{Kravtchenko2015} demonstrated that if a speaker says, ``John paid the cashier!'' as part of a story about John's trip to a grocery store, adults infer that John does \emph{not} typically pay cashiers.

%Why do claims like these backfire, while most of testimony from others does not?
%We suggest that this effect depends on the shared beliefs between interlocutors as well the details of these beliefs in terms of the \emph{a priori} likelihood of the asserted content.
%Communication in general is successful only when interlocutors share common ground \cite{Clark1996}.  
%In this paper, we formalize pragmatic language models wherein speaker and hearer both do not and do not share common ground.
%The pair of models predicts that utterances should backfire when common ground is \emph{not} symmetric between interlocutors, but that when common ground is shared, typical learning from testimony will result.
%In Expt.~1, we conceptually replicate \citeA{Kravtchenko2015}, who first demonstrated the basic \emph{backfiring} effect, and test the novel prediction about common ground made our model family. 
%The model that displays the backfiring effect (common ground asymmetric) predicts the quantitative degree of backfiring contingent on the prior probability of the event occurring. 
%We test the quantitative predictions of this model in Expt.~2. 

%, and test the qualitative predictions of these alternative models in Experiment 1,

%We also show that utterances will \emph{not} backfire when uncertainty about information in common ground is expressed, or when an utterance is removed from a conversational context, in which case there is no longer any pressure to be informative.  In


%In the present study, we directly test these predictions.  First, we develop a computational model to explain when and how utterances backfire.  In Experiment 1, we conceptually replicate previous findings that utterances will backfire when a speaker presupposes common ground that is not actually shared by the listener.   Experiment 2, we demonstrate that the strength (and presence) of backfiring varies according to the strength of the prior beliefs that are redundant with the utterance.  Finally, we show that our model predicts the results of each of these experiments.
 
%All of these inferences are based on the fact that the utterance conveys redundant, or semantically uninformative, information.
%In order to make the speech-act informative, listeners are wont to revise common ground, calling into question the behavior or habit that would otherwise ``go without saying''.




%This phenomenon--that utterances can ``backfire'' (i.e., decrease listeners' beliefs in a proposition by virtue of asserting it)--is vexing when paired alongside the incredible human capacity to learn from examples and testimony. 
%Why is it that a speaker asserting a claim can be taken both as evidence for that claim and against that claim, depending on the situation? 
%We suggest this inference depends on what is in common ground in the communicative context, and formalize the backfiring inference in a probabilistic model of language understanding.

%To date, this inferential process, or "√¢‚Äö¬¨√Ö%‚Äúbackfiring"√¢‚Äö¬¨√Ç¬ù linguistic effect, has received little attention in the literature.  In fact, most theories of language processing assert the opposite: if a person hears that Nixon is not a crook, then they should update their belief about Nixon to include this information... \red{EDIT}.  A few studies, however, provide preliminary evidence that utterances that are redundant with a listener'√¢‚Äö¬¨√¢‚Äû¬¢s preexisting beliefs do cause listeners to search for ways to make those utterances informative \cite{Yandell1979, Wegner1981, Gruenfeld1992, Kravtchenko2015}.  This process ultimately undermines the utterances' literal meanings.  
%%\citeA{Wegner1981}, for example, demonstrated that newspaper headlines such as "√¢‚Äö¬¨√Ö%‚ÄúBob Talbert is not linked to the Mafia" [CHECK] cause adults to have a more negative impression of Bob than they would otherwise, despite not explicitly asserting any incriminating information--indeed, despite denying incriminating information.  Here, since the default assumption is that people are not typically linked to the mafia, this headline is not immediately informative.  As a result, adults construct a context that \emph{would} make the headline informative, namely, one in which Bob is known to be a bad person.  
%%\citeA{Gruenfeld1992} went even further to show that uninformative newspaper headlines can actually cause people to believe the exact opposite of what those headlines claim.  After reading the headline "√¢‚Äö¬¨√Ö%‚ÄúRobert Kennedy was not planning the assassination of Fidel Castro"√¢‚Äö¬¨√Ç¬ù, for example, which denies a proposition that adults \emph{a priori} should not believe, adults in their study more strongly believed that Robert Kennedy \emph{was} planning to assassinate Fidel Castro.


%Observing a new roommate wash her dishes right after using them is a good sign because it is indicative of an underlying, positive habit: always doing one's dishes.
%The human capacity to generalize from examples such as this is the foundation for learning about the world's categories \cite{Markman1989} and people \cite<e.g.>{Seiver2013}. 
%; children as young as X, for instance, engage in this kind of inductive reasoning to infer people's preferences and reliability \red{(CITE)}.  If a person  selects five toy frogs from a bucket that contains mostly toy ducks, then that person must prefer toy frogs.
%Testimony further augments these inferences; indeed, it is necessary for learning about events one is unable to witness.
%We need not observe the roommate wash her dishes to infer that she might often do so, but rather can be told by a reliable speaker that the roommate has this habit \red{(Harris et al)}.  %\cite<e.g.>{Gelman1999}.
%The power of language to convey events and promote generalization, however, is not entirely straightforward.  If a speaker says, ``My roommate washed her dishes," to a listener who would have already expected that event to occur, for instance, then the listener  might infer that the roommate does \emph{not} typically wash her dishes; otherwise, the speaker's utterance would not have been informative \cite{Grice1975}.

%Language thus serves as useful and powerful way of conveying events and promoting generalization.
%\red{ekc: I actually think we should go back to a real-world example here.  I'm nervous this isn't exactly an exciting way to start the paper.}

%\ndg{this paragraph is good so far, but should end with an introduction to the theme of this paper. perhaps need to pivot to point out that the linguistic machinery that make it possible to convey generalization can also have unintended consequences?}
%\begin{figure}
%\centering
   % \includegraphics[width=\columnwidth]{cartoon-2}
    %\caption{
       % \small
%How does a learner interpret evidence of an event, when she is uncertain about what could have given rise to the event (a reliable cause [red] or an unreliable cause [blue])? 
%  If a listener has uncertainty about what has given rise to an event (a reliable cause [red] or an unreliable cause [blue]), observing the event is relatively more evidence for the reliable cause (red).
%In a communicative context, a speaker who asserts that the event occurred will lead the speaker to believe the reliable cause (red) was responsible, if the listener believes the speaker is represented her uncertainty correctly (Aligned).
   %Observing the event occur is relatively more evidence for the reliable cause [red]. 
   % In communication, hearing about an event provides the same evidence when the listener believes the speaker represents her uncertainty accurately (Aligned common ground).
 %  If, instead, the listener believes the speaker is presupposing some information, the listener will be led to believe the unreliable cause [blue] gave rise to the event, as that is a more informative utterance (Misaligned).
%    When speaker and listener have common ground that is not aligned, the speaker will be interpreted as presupposing one of the possible causes, and could provide evidence for a cause that would \emph{not} reliably given rise to the event (blue).
   % }
%  \label{fig:cartoon}
%\end{figure}
%, and communicative principles (i.e., that speakers will provide truthful, relevant, and informative information) strengthen the inferences one can draw from speech acts \cite{Grice1975}.  <--DO WE NEED THIS?
%\red{DOES THIS SEEM RIGHT?}




\section{Formalizing backfiring language}

%% NOTE: CUT from intro, maybe will be better in model section 
%Although interlocutors often directly manage information that is in common ground by expressing lack of understanding, they can also use the conversational principle that utterances should be both relevant and informative \cite{Grice1975} to infer the knowledge that a speaker is presupposing in a given utterance.
%For example, for a speaker to assert \emph{It was Percival who piqued the professor}, the speaker must believe that the listener already knows that \emph{somebody} had piqued the professor \cite{Clark1977}.  But if the listener actually lacks this knowledge, the exchange does not fall apart; instead, the listener can accommodate the utterance by adjusting the common ground between herself and the speaker, inferring that it must be commonly known that someone had piqued the professor (von Fintel?).  Thus, upon hearing Nixon state, ``I am not a crook," a listener unaware of any scandals surrounding Nixon may adjust the information in common ground to include an accusation that Nixon \emph{was} involved in criminal activity, thereby tainting their impression of Nixon.
%
%One important prediction of this theory, then, is that this backfiring effect should disappear if the listener's uncertainty about what is in common ground is made explicit.  If, for instance, an official needed to know whether Nixon was a crook as part of a background check for serving as President, and Nixon replied, ``No, I am not a crook," then the utterance would be established as semantically informative for the listener.  As a result, it would no longer presuppose any accusation against Nixon.  Another important prediction is that the strength of the backfiring effect should vary according to the strength of the prior beliefs that are redundant with the utterance.  The more strongly one believes that people by default are not crooks, for example, the less informative the statement, ``I am not a crook," should be.


Observing an individual participate in an event can be taken as evidence for that individual \emph{typically} participating in that event, or having the habit $h$ of doing behavior $b$. 
%event occur multiple times can be evidence for an underlying cause that could reliably give rise to the event.
%\red{An event that occurs multiple times can suggest that there is an underlying cause that reliably gives rise to the event?  Do we want a concrete example here?  If a bus shows up late to a bus stop three days in a row, for example, then it is probably part of a poorly run public transportation system.}
%Indeed, observing just one instance of an event is relatively stronger evidence for a reliable cause than an unreliable cause, all else being equal.
%\red{Indeed, an event that occurs only once is relatively stronger evidence for a reliable cause than an unreliable cause, all else being equal?}
%Similarly, observing a behavior $b$ in a person can be taken as evidence for an underlying habit $h$. 
For example, seeing a student turn in her homework provides some evidence that the student usually turns in her homework. 
It is a more likely explanation than the alternative.

%For example, if you are waiting for a bus that ends up being 15 minutes late, it is reasonable to fear it may be late the next day; public transit in this town may be unreliable. 
%disembark in a novel location to find it raining, it is reasonable to fear it may be raining in five minutes. 
%Raining events are correlated with future raining events, and this place might well be a rainy place. 

We formalize this using a simple Bayesian model:
\begin{eqnarray}
P(h \mid b) \propto P(b \mid h) P(h) \label{eq:bayes}
\end{eqnarray}
As a habit is more likely to give rise to the behavior --- as $P(b \mid h)$ gets large --- so too does the behavior become more indicative of the habit, assuming the prior probabilities are constant. 

Knowledge about an event can also come from a helpful interlocutor.
When a speaker accurately represents the listener's prior knowledge (e.g., the listener and speaker are close friends; or the listener makes explicit her prior knowledge to the speaker by asking ``Did $b$ happen?'', ``Did your student turn in his homework today?''), communicating the behavior (e.g. ``My student turned in his homework today'') can lead the listener to believe the underlying habit (here, that the student \emph{typically} turns in his homework) more strongly. 
However, when a speaker misrepresents the listener's knowledge (e.g., the speaker believes the listener knows something that she has in fact forgotten, or the listener is overhearing a conversation between friends), communicating the behavior might lead the listener to believe the habit is \emph{less} likely.  If the student did usually turn in his homework, then the utterance---``My student turn in his homework today.'''---would be uninformative.  



% it is valid to assume the knowledge of the habit to be communicated is \emph{not} in common ground, but that both teacher and learner have a meta-agreement on this.
%
%\ndg{this paragraph is kind of confusing and doesn't really lead into the formal treatment. revise to emphasize (and show) how to model the three situations in the experiment.}
%In a conversational setting, knowledge of a person's habits may or may not be in common ground, and the speaker and listener may or may not be aware of this \cite{Clark1977, Clark1996}. 

%Friends may also have a mutually-understood common ground about a third person; one that an overhearer might not have. 
%This same situation occurs when one of the friends assumes a bit of knowledge that the other person doesn't have (e.g. because she forgot).
%Other communicative settings may exist, where the both levels of knowledge are not in common ground. 
%If a listener believes that the speaker is not representing her uncertainty correctly (e.g., because the listener has forgotten this bit of information or because the listener is overhearing a conversation), she can use the speech-act to help resolve what the speaker believes to be in common ground. 
%\red{we might still want a concrete example here, but can add it later}

We incorporate these inferences into Rational Speech-Acts framework \cite{Frank2012, Goodman2013}, as a lifted variable inference akin to the treatment by \citeA{Degen2015} and discussed in detail in \citeA{GoodmanLassiter}\footnote{Briefly, a ``lifted'' variable is a variable of uncertainty over which a pragmatic listener reasons. The inference incorporates general pragmatic principles of communication, by assuming the speaker intended a particular value of that random variable.}.
%
The \textbf{backfiring} RSA model is:  
\begin{eqnarray}
&&P_{L_1}(b, h \mid u)\propto P_{S_1}(u \mid b, h)\cdot P(b \mid h) \cdot P(h) \label{eq:L1}\\
&&P_{S_1}(u \mid b, h) \propto \mathrm{exp}({\alpha \ln P_{L_0}(b \mid u, h))} \label{eq:S1}\\
&&P_{L_0}(b \mid u, h)\propto \denote{u}(b) \cdot P(b \mid h) \label{eq:L0}
\end{eqnarray}
%
We assume the set of utterances are remarks about the event or behavior occurring or not --- $b$ or $\neg b$--- as well as the possibility of not remarking on the situation, a \emph{null} utterance that has no information content.  

The prior probability of a behavior depends on the habits of the person. For demonstrative purposes, we assume that the if the habit $h$ is present, the behavior has a high probability of occurring; if the habit is absent, the probability is lower. 
\begin{eqnarray}
P(b \mid h) = \begin{cases}
\lambda_{h}  & \text{if } h\\
\lambda_{\neg h}  & \text{if not } h
\end{cases} \label{eq:hab}
\end{eqnarray}
where $\lambda_{h} > \lambda_{\neg h}$.
The model is implemented in the probabilistic programming language WebPPL \cite{dippl}, and a simple version can be seen at \mht{add forest page}.

\begin{figure}
\centering
    \includegraphics[width=\columnwidth]{schematic-model}
    \caption{Schematic model predictions.
    \mht{Figure to be revised}
    Observing or hearing a proposition when speaker and listener share common ground provides evidence for the underlying habit (green and red bars $> 0$). 
    When common ground is not shared, hearing a proposition provides evidence \emph{against} the underlying habit (blue bars $<0$).
    Additionally, when the prior beliefs about a habit are least informed (prior probability around 0.5), a single observation of the behavior carries a lot of evidence, relative to when prior beliefs are more informed. 
    The opposite is true when words backfire: The stronger the \emph{a priori} belief in the habit, the more the utterance conveys evidence against that habit. }
  \label{fig:schematic-model}
\end{figure}


The model predicts that when a speaker does not represent a listener's beliefs accurately, utterances affirming an event will be interpreted as expressing atypical behavior by implicitly implying the habit is not present ($\neg h$).
The statement, ``My student turned in his homework today,'' for instance, should suggest that the student does \emph{not} usually turn in his homework (Figure \ref{fig:schematic-model} \mht{figure to be revised}).
%This occurs when the speaker does not represent the listener's beliefs accurately.
%The strength of this inference is predicted to be modulated the listener's \emph{a priori} belief in the habit; the stronger the listener believes it to be the case that the roommate usually washes her dishes, the more the utterance \emph{My roommate washed her dishes today} will backfire. 

\subsection{Alternative models}

The backfiring inference depends critically on a misunderstanding of common ground. 
If a listener explicitly asks, for example, ``Did your student turn in his homework today?'' then the speaker will learn that the listener is unsure of the student's habits\footnote{It is also important that the question be asked for plausible reasons that do not imply that the listener believes the habit to be absent (i.e., that the student doesn't usually turn in his homework).}.  As a result, the response, ``My student turned in his homework today,'' will become semantically informative, no longer presupposing the listener knows about the student's habits.
Figure \ref{fig:schematic-model} (green bars) shows what happens when the speaker and listener are both aware of the listener's knowledge.
This is more akin to pedagogical communication, where teacher and learner are on the same page. 
The \textbf{instructive} RSA model is:
\begin{eqnarray}
&&P_{L_1}(b, h \mid u)\propto P_{S_1}(u \mid b)\cdot P(b \mid h) \cdot P(h) \label{eq:L1mod}\\
&&P_{S_1}(u \mid b) \propto \mathrm{exp}({\alpha \ln P_{L_0}(b, h \mid u))} \label{eq:S1mod}\\
&&P_{L_0}(b, h \mid u)\propto \denote{u}(b) \cdot P(b \mid h) \label{eq:L0mod}
\end{eqnarray}
\mht{double check}

Another context in which we would not expect evidence to backfire is observational learning.
Here, we would expect observing the student turning in his homework to be taken as evidence that he usually does his homework. 
These predictions are borne out in a standard model of Bayesian learning (Eq.~\ref{eq:bayes}, Figure \ref{fig:schematic-model}, red bars).
\ndg{does the model predict a differences between observation and pedagogy? (it should.) cite shafto, goodman, frank for this. indicate more clearly the difference between the istructive context and the misaligned CG one... indicate why and when the listener has to accommodate by adjusting prior beliefs in order to make a statement cooperative.}
\mht{it does not; this may be because the utterances ("b", or "not b") are perfectly informative about the world...}

%This captures the interesting issue in communicative situations wherein if an event often occurs, then----assuming the listener and speaker both have this knowledge in common ground---it is not informative to remark on it. 
%Thus, a speaker who deliberately remarks ``My roommate did her dishes today.'' should believe that usually her roommate does not do her dishes, and believe his listener to believe this as well. 
%A listener who does not actually know whether or not the speaker's roommate usually does her dishes will interpret the utterance as implicating that the roommate does not usually do her dishes.
%We refer to the phenomena that a speech-act about an event can provide evidence against an underlying cause that would reliable give rise to the event as \emph{backfiring}. 

%We formalize the backfiring inference as a probabilistic model of pragmatic communication where listener and speaker do not share common ground. 


\section{Experiment 1: Conceptual replication and extension of \citeA{Kravtchenko2015}}

%\ndg{motivate experiment more clearly in terms of the modeling, and in terms of advances over previous work...}

In our first experiment, we tested the qualitative predictions of the three models (backfiring, instructive, and observation)

\begin{enumerate}
\item Backfiring should occur in conversational contexts in which a speaker presupposes common ground that a listener actually lacks (e.g., when a speaker states, ``My student turned in his homework today," to a listener who is not aware of the student's typical habits; Eq.~\ref{eq:L1});
\item Backfiring should \emph{not} occur in conversational contexts in which a listener makes it clear that she is uncertain about a habit (e.g., when the listener explicitly asks the speaker if the student turned in his homework; Eq.~\ref{eq:L1mod}); and
\item Backfiring should \emph{not} occur in non-conversational contexts (e.g., when the listener simply observes that the speaker's student turned in his homework; Eq.~\ref{eq:bayes}).
\end{enumerate}
%ask whether directly manipulating the common ground between interlocutors and the  influences adults' interpretations of affirmations (e.g., \emph{My roommate did her dishes today.}).
%We measured interpretations both when the speaker believes the habit is in common ground and when the listener makes explicit that this is not in common ground.
%Additionally, we included a control condition where the event is observed rather than uttered. 
%We tested the qualitative predictions of the pragmatics model that backfiring:
%\begin{enumerate}
%\item should occur in communicative settings where speaker and listener do not share either types of common ground (e.g., the speaker states, "My student turned in his homework on time today," while assuming that the listener knows who her student is)
%\item should not occur in communicative settings where the higher-order uncertainty about \emph{whether the event usually} occurs is in common ground (e.g., when the listener explicitly asks the speaker if the student turned in his homework on time, and the speaker replies, "Yes, my student turned in his homework on time today"); and 
%\item should not occur in settings where the lower-order uncertainty about the particular event occurring or not that are not explicitly communicative (e.g., when the listener simply observes that the speaker's student turned in his homework on time today). \end{enumerate}
%Our study includes sixteen items that have considerable variability in the \emph{a priori} believability of the habit being present. 
%This lets us explore how inferences may be strengthened according to the strength of adults' \emph{a priori} beliefs.

%We predicted that in communicative contexts, adults should interpret the affirmations as expressing atypical behavior (e.g., the student does not typically turn in her homework on time).  In non-communicative contexts, on the other hand, adults should interpret the utterance as reflecting typical behavior, since in these contexts there is no conversational pressure to be informative.  Instead, according to standard Bayesian reasoning(???), the affirmation should serve as evidence that the person does tend to engage in that behavior.

%In non-communicative contexts, on the other hand, adults should interpret the utterance as reflecting typical behavior, since in these contexts there is no conversational pressure to be informative.  
%Instead, according to standard Bayesian reasoning(???), the affirmation should serve as evidence that the person does tend to engage in that behavior.

\subsection{Method}

We performed a power analysis using a pilot experiment run on a subset of items to determine that we should collect 120 participants to achieve 0.95 power. 

\subsubsection{Participants}

Participants were 120 workers from Amazon's Mechanical Turk platform. 
All had at least a 95\% work approval rating.
The task took about 5 minutes and participants were compensated \$0.60.

\subsubsection{Materials}

Four versions of sixteen contexts were created (64 items in total). 
Each of the four versions was a different within-subjects condition, corresponding to the backfiring model and the two alternative models (instructive and observation) as well as a prior or baseline measurement. 
Participants completed a series of 16 randomly drawn trials from this group of 64, which were evenly distributed across conditions and included only one version of each context (i.e., participants never saw two versions of the same context).  
Trials were presented in random order.

\subsubsection{Procedure}

On each trial, participants read about Person A who could not remember either a person or a business related to Person B, and was introduced to two alternatives. 
One of the alternatives was described as ``always'' \textsc{does x}, and the other alternative as ``only occasionally'' \textsc{does x}. 
For example:
%\textbf{Context.} 
\begin{quote}
Molly is having a hard time remembering which student her officemate is tutoring.  
She knows it is either Tom or Jim. 
Tom, she knows, always turns in his homework on time.  
Jim, she knows, only occasionally turns in his homework on time.
\end{quote}

In the \emph{Baseline} condition, no additional information was provided, and participants were asked: ``Who/what is the person/business related to Person B?'' (e.g., Who is Molly's officemate tutoring?). 

In the three experimental conditions (backfiring, instructive, and observation), participants read additional information that varied according to the condition.

In the \emph{Backfiring} condition, Person B utters that the event occurred.
In the officemate scenario, for example, participants read, ``In their office, Molly's officemate says to her, `My student turned in his homework on time today.'"

In the \emph{Instructive} condition, Person A is trying to accomplish some unrelated goal and explicitly asks whether an event happened, to which Person B responds that it occurred.  In the officemate scenario, this was: ``In their office, Molly helps her officemate fill out a daily report card for her student, while her officemate files away some papers.  Molly reads out loud from the report card,`ìDid your student turn in his homework on time today?'  Her officemate replies, `Yes. My student turned in his homework on time today.'"

In the \emph{Observation} condition, Person A observes that the event occurred. 
Participants read, for example, ``In their office, Molly notices some papers on her officemate's desk.  Her officemate's student turned in his homework on time today."

Participants selected one of the two options (e.g., Tom or Jim) and then rated their confidence in their choice with a slider bar.
The experiment in full can be viewed at \url{http://stanford.edu/~mtessler/backfiring-words/experiments/2afc/forcedchoice-1.html}.

%Person A makes explicit that they do not know whether \textsc{X happened} today (e.g., by asking a question from a survey), and Person B clarifies for Person A \emph{X happened}.
%In the \textbf{observation} condition, Person B simply observes evidence that \emph{X happened.}.
%\ndg{it would be useful to have examples of each, space permitting. otherwise it's kind of hard to follow...}


%On one trial, for example, participants read the following scenario: √É¬¢√¢‚Äö¬¨√Ö%‚Äú√É¬¢√¢‚Äö¬¨√Ç¬ù  Participants then had to decide who they thought the officemate√É¬¢√¢‚Äö¬¨√¢‚Äû¬¢s student was--Tom or Jim--without any other information and rate their confidence in their decision on a sliding scale.  All trials had the same structure: a character having trouble remembering information, and then a description of two options, one of which always engages in a behavior, and one of which only occasionally engages in a behavior.
%
%Pragmatic condition. The Pragmatic condition was identical to the Baseline condition, except a brief utterance was added to the vignette after the description of the two options.  In the officemate scenario, for example, participants read, √É¬¢√¢‚Äö¬¨√Ö%‚ÄúIn their office, Molly√É¬¢√¢‚Äö¬¨√¢‚Äû¬¢s officemate says to her, √É¬¢√¢‚Äö¬¨√ã≈ìMy student turned in his homework on time today.√É¬¢√¢‚Äö¬¨√¢‚Äû¬¢√É¬¢√¢‚Äö¬¨√Ç¬ù  We predicted that in this condition adults should be more likely to state, relative to baseline, that the officemate√É¬¢√¢‚Äö¬¨√¢‚Äû¬¢s student is the one who only occasionally turns in his homework on time, since that context would make the utterance informative.
%
%Literal condition. The Literal condition was the same as the Pragmatic condition, except an observation was added after the description of the two options rather than an utterance.  In the officemate scenario, this observation was, √É¬¢√¢‚Äö¬¨√Ö%‚ÄúIn their office, Molly notices some papers on her officemate's desk. Her officemate's student turned in his homework on time today.√É¬¢√¢‚Äö¬¨√Ç¬ù  Here, the same content is expressed--the student turned in his homework on time today--but it is no longer part of a conversation.  Thus, adults should be somewhat biased, relative to baseline, to select the student who always turns in his homework on time, since this evidence is most consistent with that behavior.
%
%Speaker Manipulation condition.  The Speaker Manipulation condition was also the same as the Pragmatic condition, except the utterance added was no longer in a communicative context(??).  Participants read, for example, √É¬¢√¢‚Äö¬¨√Ö%‚ÄúIn their office, Molly helps her officemate fill out a daily report card for her student, while her officemate files away some papers.  Molly reads out loud from the report card, √É¬¢√¢‚Äö¬¨√ã≈ìDid your student turn in his homework on time today?√É¬¢√¢‚Äö¬¨√¢‚Äû¬¢  Her officemate replies, √É¬¢√¢‚Äö¬¨√ã≈ìYes. My student turned in his homework on time today.√É¬¢√¢‚Äö¬¨√¢‚Äû¬¢√É¬¢√¢‚Äö¬¨√Ç¬ù  Because the sentence, √É¬¢√¢‚Äö¬¨√Ö%‚ÄúMy student turned in his homework on time today,√É¬¢√¢‚Äö¬¨√Ç¬ù is now a response to a question on a report card rather than a spontaneous communicative act, it does not have any pragmatic implications.  As a result, participants should again be somewhat biased to select the student who always turns in his homework on time.


\subsection{Behavioral results and discussion}


\begin{figure*}
%\centering
    \includegraphics[width=\textwidth]{expt1-3responses}
    \caption{Endorsement scores, forced choice proportions and confidence ratings for each condition in Experiment 1. Dotted lines denote chance levels. Error bars denote bootstrapped 95\% confidence intervals. \mht{need to change condition names}}
  \label{fig:expt1-all}
\end{figure*}



We computed an \emph{endorsement score} by scaling forced-choice responses by their associated confidence level. 
We coded the selection of the more \emph{likely} response given an observation (e.g., the student who \emph{always} does turns in his homework on time) as a 1; the other option as -1.
We fit the \emph{endorsement score} data using a generalized mixed-effects model with random by-participant effects of intercept and random by-item effects of intercept\footnote{This was the maximal-model that our data permitted.}. 
As predicted, participants endorsed the likely response \emph{less} in the \emph{Backfiring} condition (M=-0.09; bootstrapped 95\% CI [-0.15, -0.03]) than the in the \emph{Baseline} condition (M=0.18 [0.14,0.22]), $\beta = -0.24; SE = 0.03; t = -8.3$.
%$\beta = -0.24; SE = 0.03; t(1794) = -8.3; p<0.001$
There was a trend for participants to endorse the likely response \emph{slightly more} in the \emph{Observation} condition (M=0.24 [0.18, 0.29]) than in the \emph{Baseline} condition ($\beta = 0.05; SE = 0.03; t = 1.73$). 
No such trend was observed for the \emph{Instructive} condition (M=0.18 [0.13, 0.24]). 


%  condition       mean   ci_lower   ci_upper
%       (fctr)      (dbl)      (dbl)      (dbl)
%1       prior  0.1802500  0.1381531  0.2228339
%2 observation  0.2382083  0.1821380  0.2905667
%3    backfire -0.0935625 -0.1521505 -0.0345349
%4      survey  0.1887708  0.1343135  0.2415599
%Linear mixed model fit by REML 
%t-tests use  Satterthwaite approximations to degrees of freedom ['lmerMod']
%Formula: score ~ condition + (1 | workerid) + (1 | item)
%   Data: d0
%
%REML criterion at convergence: 3099.8
%
%Scaled residuals: 
%    Min      1Q  Median      3Q     Max 
%-2.5099 -0.8025  0.1406  0.7323  2.9124 
%
%Random effects:
% Groups   Name        Variance Std.Dev.
% workerid (Intercept) 0.077443 0.27829 
% item     (Intercept) 0.001255 0.03542 
% Residual             0.260483 0.51038 
%Number of obs: 1920, groups:  workerid, 120; item, 16
%
%Fixed effects:
%                       Estimate Std. Error         df t value Pr(>|t|)    
%(Intercept)           1.807e-01  3.561e-02  1.936e+02   5.075 9.04e-07 ***
%conditionobservation  5.702e-02  3.300e-02  1.796e+03   1.728   0.0842 .  
%conditionbackfire    -2.731e-01  3.299e-02  1.794e+03  -8.277 2.22e-16 ***
%conditionsurvey       6.817e-03  3.302e-02  1.797e+03   0.206   0.8364    

To better understand the nature of the effect, 
we further analyzed the data separately in terms of (1) the proportion of participants who selected the more \emph{likely} option given an observation (e.g. the roommate who \emph{always} does her dishes) and (2) the confidence ratings.
Critically, participants were significantly \emph{less} likely to choose the ``likely''ù option in the \emph{Backfiring} condition than in the \emph{Baseline} condition ($\beta = -1.42; SE = 0.15; z=-9.0;$).  % p < .001%
Interestingly, however, participants were \emph{no more} likely to choose the ``likely'' option in either the \emph{Observation} or \emph{Instructive} conditions than at baseline (Figure \ref{fig:expt1-all}; middle panel).
% backfiring (M=0.46 [0.41, 0.50]) 
% baseline (M=0.71 [0.67,0.75])
% observation (M=0.71 [0.68, 0.75]) 
% instructive (M=0.68 [0.63,0.71]) conditions than in the Baseline (Figure \ref{fig:expt1-all}; middle panel).
Finally, since participants are not given any helpful information in the \emph{Baseline} condition, we expected the confidence rating data to be lower in the \emph{Baseline} condition than in the three experimental conditions.
In all conditions, this was the case (Figure \ref{fig:expt1-all}; right panel).


%: Prior 0.39 [0.36, 0.42] vs. Observation 0.60 [0.58, 0.62], Ignorant Speaker 0.60 [0.58, 0.61], Backfiring 0.62 [0.61, 0.64] 
Overall, participants in the \emph{Backfiring} condition interpreted utterances as expressing atypical events relative to the other three conditions as predicted by our models and conceptually replicating \citeA{Kravtchenko2015}.  If an officemate states, ``My student turned in his homework today," then the student must not typically turn in his homework.  However, we also expected participants in the \emph{Observation} and \emph{Instructive} conditions to interpret the target statements as evidence that the relevant behavior \emph{does} typically occur more often than in the \emph{Baseline} condition, which we did not find. 
% Upon reading an observation that a student turned in his homework, for instance, we expected participants to be more likely to believe that the student usually turns in his homework, relative to baseline.  We also expected participants to interpret the statement, ``My student turned in his homework today," as evidence that the student usually turns in his homework when produced in response to a question about whether the student turned in his homework.  Instead, participants in these two conditions did not differ from those in the \emph{Baseline} condition.  
This lack of differences could be due to participants having a strong prior belief that the option that was more likely given the evidence was also more likely \emph{a priori}. 
We observed a baseline probability reliably greater than 50\% for 8 out of the 16 items.
In addition, participants might have interpreted the observation and instructive vignettes as suggestions \emph{from the experimenter} that the habit was unlikely, and thus those conditions might have backfired, as well (e.g., some participants might have asked themselves, \emph{why is the experimenter going through all this trouble to tell me that the event occurred?}) \mht{cite ransom et al., experimenter effects in reasoning?}.
We designed the next experiment to get around some of these issues.

%Two possible explanations for this lack of differences are: 1) prior beliefs could have already been relatively high, making it difficult for linguistic and observational evidence to influence responses, and 2) participants might have needed more than one piece of evidence to make a strong generalization about behavior.

%\red{do we need the median split?  could it be enough to just say, yeah, the observation and ignorant speaker conditions were funky because overall, prior beliefs were pretty high?  and then focus on the most important / interesting topic, which is the backfiring} fact that we observe an effect in the Backfiring condition but not in the other conditions might in fact be expected if the items for which the prior beliefs are the strongest show a relatively small effect of evidence compared to when prior beliefs are the weakest.
%The opposite pattern would be expected for the Backfiring condition, where it is predicted an utterance will backfire the most when the prior beliefs are the strongest (see Figure \ref{fig:schematic-model}) for model predictions).
%To this end, we performed a median split of the items based on their prior endorsement. 
%Figure \ref{fig:expt1-medspilt} shows mean endorsement score in each of the three conditions against the backdrop of the prior endorsement score, when the items are split based on prior endorsement. 
%We see a larger deviation from the prior for the Observation and Ignorant Speaker conditions and a smaller deviation from prior for the Backfiring condition, when the prior is relatively weak. 
%The opposite pattern is observed when prior beliefs are relatively stronger, as predicted by the theory (Figure \ref{fig:schematic-model}). 

%\ndg{think through the best way to analyze / present the relation to prior....}



%    condition      mean  ci_lower  ci_upper
%       (fctr)     (dbl)     (dbl)     (dbl)
%1       prior 0.3923750 0.3643260 0.4193974
%2 observation 0.6030833 0.5833073 0.6184844
%3    backfire 0.6291875 0.6102781 0.6488406
%4      survey 0.5956458 0.5757083 0.6145448



%\begin{figure}
%\centering
   % \includegraphics[width=\columnwidth]{fc2-score-medSplit}
    %\caption{Median split of the data based on endorsement score in the Prior condition. 
    %Dotted lines denote mean prior levels with 95\% CIs.}
  %\label{fig:expt1-medspilt}
%\end{figure}







% neither the observational data nor the utterance when common ground is aligned have an effect above and beyond the prior is not surprising \emph{if}  
%
%We were somewhat surprised to \emph{not} find an effect of the observational data or the utterance when common ground is aligned on the endorsement of the more likely response above and beyond the prior endorsement. 
%
%Reading, for example, "My student turned in his homework on time today,"√¢‚Äö¬¨√Ç¬ù in a communicative context caused participants to infer that the student does not typically turn in his homework on time.  
%Adults were also more confident in their choices in the Pragmatic condition (M = .63, SE = XX, n = XX) than in the Baseline condition (M = .39, SE = XX, n = XX).
%
%
%To determine how the Pragmatic, Literal, and Speaker Manipulation conditions compared to the Baseline condition, we fit the data using mixed-effects regression models comparing the responses and confidence ratings of the experimental conditions to those of the Baseline condition.  
%Each model had a fixed effect of condition and random effects of item and participant.  
%To test for the significance of effects, we performed likelihood ratio tests. 
%Chi-squared values, degrees of freedom, and p-values, all from the likelihood ratio test, are reported for each statistical test.
%
%
%The Literal (M = .71, SE = XX, n = XX) and Speaker Manipulation (M = .68,  SE = XX, n = XX) conditions, however, did not differ significantly from the Baseline condition, √É¬è√¢‚Ç¨¬°2(1) = 0, p = .98, and √É¬è√¢‚Ç¨¬°2(1) = 2.11, p = .15, respectively, even though we expected participants in these conditions to be more likely to choose the "likely"√¢‚Äö¬¨√Ç¬ù option.  One possibility is that for the items in this task, there was not much room for preference for the "likely"√¢‚Äö¬¨√Ç¬ù option to strengthen, given that participants already preferred the "likely"√¢‚Äö¬¨√Ç¬ù option in the Baseline condition at above-chance levels, t(119) = 9.05, p < .001.  Confidence ratings, however, did distinguish among these conditions.  Confidence ratings in both conditions (M = .60, SE = XX, n = XX in the Literal condition; M = .60, SE = XX, n = XX in the Speaker Manipulation condition) were significantly higher than confidence ratings in the Baseline condition,  √É¬è√¢‚Ç¨¬°2(1) = 275.41, p <.001, and √É¬è√¢‚Ç¨¬°2(1) = 255.68, p < .001, respectively.  Thus, the evidence provided in these two experimental conditions made adults at least more confident in their choices.  
%
%POST-HOC ANALYSES?
%To determine how pre-existing biases might influence participants'√¢‚Äö¬¨√¢‚Äû¬¢ responses in each of our conditions, we performed a median split analysis, separating items in the Baseline condition for which participants had weak preferences (M  = XXXX) from those for which participants had strong preferences (M = XXXX).  


%\subsection{Quantitative model evaluation} \red{TAKE OUT?}

%The formal pragmatics model in Eq.~\ref{eq:L1} describes how a listener is likely to interpret an utterance affirming an event, when she believes the speaker to have presupposed some information. 
%Since there is appreciable variability in participants' ratings in the Prior condition, we can use those ratings as $P(h)$ and explore the quantitative predictive power of the model.
%We assume, for simplicity, that the various habits described in the experimental context give rise to their associated behaviors --- $P(b \mid h)$ --- as given in Eq.~\ref{eq:hab}.
%We model the Observation data using Eq.~\ref{eq:bayes}, the Misaligned CG data using Eq.~\ref{eq:L1} and the Aligned CG data using Eq.~\ref{eq:L1mod}.

%The model has one remaining parameter: the speaker optimality parameter in Eqs.~\ref{eq:S1} and \ref{eq:S1mod}. 
%We assume these two parameters are the same in this analysis, and infer its credible value using Bayesian data analytic techniques \cite{LW2014}. 
%The posterior predictive distribution marginalizes over the likely parameter values to produce predictions about what the data should look like given the pragmatics model and the observed data. 
%This is akin to fitting the parameters and is an important step in model validation as it shows what data is actually predicted by the model.
%We compare the posterior predictive distribution over the probabilities of producing the \emph{likely} response to the empirical means for each item and condition (Figure \ref{fig:scatter}). 
%The model provides a reasonable quantitative fit to the empirical data ($r(48) = 0.82$), though the fit is far from perfect.

%One issue is that there is not an a lot of reliable variability in the human judgments within the different conditions, most notably in the Misaligned CG condition. 
%We also seem to be doing the worst job capturing the data from the Observation condition using Eq.~\ref{eq:bayes}. 
%This may be an artifact of the task: In order to present observational data to the participant, we used extended vignettes to explain how the protagonist was able to notice the event occur. 
%Such an elaborate cover story may have raised the question to the participants of why the experimenter to choosing to supply this information. 
%This may inadvertently have led to a \emph{backfiring} effect for some of the items.

%\ndg{is it possible to get a wider range of predicted values from the (unaligned) model? if so, it would be worth running the corresponding experiment....}

%\begin{figure}
   % \includegraphics[width=\columnwidth]{scatter}
    %\caption{Model predictions and the associated human endorsements.}
  %\label{fig:scatter}
%\end{figure}


%\section{Experiment 2} 
%Experiment 1 demonstrated the existence of a backfiring effect as a speech-act of what would usually be construed of as positive evidence: the observation of an event. 
%In Experiment 2, we explore downstream consequences of this inference. 
%If intuitive, structured theories of world are what guide inference, then we would expect to observe the effects of backfiring in different components of that structured konwledge.
%For example, If habits have a causal dependence on some more abstract trait, then having one's belief shaken in a person's habit can have belief shaken in the upstream trait. 
%For instance, upon hearing one's friend say \emph{My roommate did her dishes today.}, a hearer could plausibly infer both this an irregular event and that the roommate is the kind of person who wouldn't normally do her dishes. 
%That is, the roommate's room might also be a mess, she might be an inconsiderate person, or maybe more likely than not to fall delinquent on her rent checks.

%This opens the door for manifestly different types of conceptual learning from language. \red{This is a good point, but I feel like we'll end up focusing *not* on language (and instead on the relation between irregular events and traits)... which maybe is ok, I don't know.}


%
\section{Experiment 2: Degrees of backfiring}

\begin{figure*}
%\centering
    \includegraphics[width=\textwidth]{minimal-1-scatters}
    \caption{Experiment 2 results. All results are on the scale of average number of times \emph{per day}. Each point represents one item (e.g. ``wears socks''). 
    Left: Observed vs. Baseline. Observed never goes below baseline (y=x line).
    Middle: Communicative vs. Baseline. Communicative goes below baseline when baseline is high. 
    Right: Communicative vs. Observed. Communicative suggests lower frequency the more an observation suggests higher frequency.
    Note: ``Smokes cigarettes'' has been removed from these plots because it messes up the scale (people smoke a lot of cigarettes per day).
    }
    
  \label{fig:expt2}
\end{figure*}


The model of backfiring language (Eq. \ref{eq:L1}) predicts that the extent to which backfiring should occur depends upon the \emph{a priori} likelihood of the action occurring. 
In our second experiment, we aimed to elicit reactions to utterances about human behaviors that vary widely in terms of their likelihood of occurring.

%human behaviors covering a wide range of likely frequencies of action, as well as to simplify and generalize the experimental paradigm. 
%modified the stimuli used in Experiment 1 to include actions associated with a wider range of prior beliefs so that we could test the quantitative predictions of our models. 
%Specifically, we ask whether the strength and presence of backfiring varies systematically according to the strength of prior beliefs. 
Our model predicts a continuum of the degree of backfiring ranging from utterances about events that are \emph{a priori} very likely (e.g., ``John wore shoes today") to events that are very unlikely (e.g., ``John climbed a mountain today"). \red{this sentence is hard to understand}

\red{OR:} In our second experiment, we modified the stimuli used in Experiment 1 to include actions associated with a wider range of prior beliefs so that we could test the quantitative predictions of our models.  Specifically, we asked whether the strength and presence of backfiring varies systematically according to the strength of prior beliefs.  Our models predict that utterances that are strongly redundant with prior beliefs (e.g., ``John wore shoes today") should backfire more than utterances that are less redundant (e.g., ``John went for a hike today"), by virtue of being less semantically informative.

\subsection{Method}

\subsubsection{Participants}
Participants were 150 workers from Amazon's Mechanical Turk platform. 
All had at least a 95\% work approval rating.
The task took about 7 minutes and participants were compensated \$0.80.

\subsubsection{Materials and procedure}
Participants were randomly assigned to one of three conditions: the \emph{Backfiring} condition, the \emph{Observation} condition, or the \emph{Baseline} condition.

In the \emph{Observation} condition, participants were told that on each trial they would be given a random fact about a person, and that they would then be asked to judge how often that person performs the action.  Each trial had the same format: ``\textsc{person} did X today'', where X was an action (e.g., ``Stephen went for a run today.'').  Participants were then asked, ``How often does \textsc{person} do X?''  (e.g., ``How often does Stephen go for runs?'').  Participants responded ``M times per K,'' by entering a number for M and choosing K from a drop-down with options week, month, year, and 5 years. 

In the \emph{Backfiring} condition, participants were instead told that they would read excerpts from conversations between friends.  
On each trial, participants read, ``You overhear two friends talking. One of them says to the other, `\textsc{person} did X today'.''

In the \emph{Baseline} condition, participants were asked to rate how often a typical person performs the action, without any other information.
%  We asked participants to assume that the typical person had performed the action at least once, so that the priors / to avoid the possibility that... \red{we should justify why we used the exact baseline we did}
%
%consisted of a single utterance: one person describing an event to a friend (e.g., ``Kelly wore socks today").  After reading each utterance, participants indicated how frequently they believed the agent in the utterance engages in the activity (e.g.,``How often does Kelly wear socks?").  Participants responded by stating \emph{X} times per week, month, year, or five years, where \emph{X} could be any number.


\subsection{Behavioral results}

Sketch of this section

We must decide on 1 (or more) definitions of backfiring
\begin{enumerate}
\item Less frequent than not knowing anything about the person (Backfire vs. Baseline)
\item Less frequent than you would think had you \emph{observed} the event (Backfire vs. Observation)
\item Less frequent than not knowing anything about the person except that they have done it at least one time in the past (Backfire vs. Prior elicitation)... this is potentially important for items like ``John smoked a cigarette today.'', wherein the typical person (Baseline) doesn't smoke at all.. This is probably only subtly different from (2)
\item Less frequent that someone who ``Does X'' (habitually; e.g. ``John smokes'' vs. ``John smoked a cigarette today.'', not measured)
\end{enumerate}


3 possible scatter plots are in Figure \ref{fig:expt2}.

\subsection{Model analysis}

Forthcoming...

\section{General Discussion}

We present a formal model for understanding how language can backfire, or imply that the content expressed is typically not true. 
The model derives predictions by revising common ground between interlocutors when a speaker produces an utterance that would otherwise be semantically uninformative.  After hearing, ``My roommate washed her dishes," for example, the model predicts that a person who does not know the roommate should infer that the roommate typically does \emph{not} wash her dishes.
%In Expt.~1, we validate that this prediction depends on the information being communicated \red{not sure what this means} as well as a misalignment of common ground between speaker and listener in conversation. This experiment also serves as a conceptual replication of \citeA{Kravtchenko2015} and adds to the body of literature demonstrating that adults try to avoid redundancy in conversation (CITE).
%Ultimately, this can result in an utterance ``backfiring",.  If a person notes, ``My roommate washed her dishes today," for example, then a listener who does not know the roommate will likely infer that the roommate does \emph{not} typically was her dishes; otherwise, the utterance would not be informative (CITE).



Our model also makes several predictions about backfiring that we tested in Experiments 1 and 2.  In Experiment 1, we showed that this effect disappears when an interlocutor elicits the target utterance by expressing uncertainty.  If a person asks their friend, ``Did your roommate wash her dishes today?" and the friend responds, ``Yes, my roommate washed her dishes today," then the utterance no longer presupposes any shared knowledge about the roommate.  The effect also disappears when the proposition is framed as an observation rather than a communicative utterance (e.g., ``She saw that the roommate washed her dishes today").  In these contexts, there is no longer any pressure for statements to be maximally informative.  As a result, even if the statement is redundant with adults' prior beliefs, adults will accept the statement as evidence that the behavior usually occurs.  Second, in Experiment 2, we demonstrated that the strength of backfiring depends on the strength of prior beliefs.  Hearing, ``Jane wore shoes today," for example, will result in stronger backfiring for a person who does not know Jane than will, ``Jane wore sandals today," because wearing shoes more strongly \emph{goes without saying}.

Ultimately, our work serves as a conceptual replication of citeA{Kravtchenko2015} and adds to the body of literature demonstrating that adults try to avoid redundancy in conversation.  


\mht{I think we should scrap this paragraph, which is a restatement of things we've said earlier, in lieu of a deeper discussion about accommodation and presupposition}
\red{ekc: ok, well some of that could be things that we removed from the introduction.  we originally had good examples in there of presupposition and accommodation, including the percival example, and could put that here instead.  but i think we do need at least a short summary of our novel findings - not just the model.}

\red{cut from intro: Although interlocutors often directly manage information that is in common ground by expressing lack of understanding, they can also use the conversational principle that utterances should be both relevant and informative \cite{Grice1975} to infer the knowledge that a speaker is presupposing in a given utterance.
For example, for a speaker to assert \emph{It was Percival who piqued the professor}, the speaker must believe that the listener already knows that \emph{somebody} had piqued the professor \cite{Clark1977}.  But if the listener actually lacks this knowledge, the exchange does not fall apart; instead, the listener can accommodate the utterance by adjusting the common ground between herself and the speaker, inferring that it must be commonly known that someone had piqued the professor (von Fintel?).}
%Our experiment serves as a conceptual replication of \citeA{Kravtchenko2015}.
%Our work expands upon theirs in the following ways: 
%(1) We include control conditions that show how the information is interpreted when it is an observation as well as when it is an utterance when common ground is aligned between speaker and listener; 
%(2) We show how the strength of the inference depends systematically on the strength of the prior;
%(3) We include a formal pragmatics model that predicts all of the above.

%presented a formal model for Common Ground inference that uses communicative principles (\emph{be truthful}, \emph{be informative}) to infer what presuppositions the speaker must have brought to conversation. 
%The model predicts that an utterance that should ``go without saying'' given one Common Ground will lead a listener to infer a different Common Ground, and result in a backfiring effect decreasing the listener's belief in the proposition being affirmed.
%The quantitative model predicts that this effect should be strongest when the \emph{a priori} beliefs in the common ground that would make the utterance uninformative are the strongest.
%This is in contrast to typical Bayesian updating, where the most information is gained when \emph{a priori} beliefs are most uncertain. 
%We validate all of these predictions in our experiment.

%We replicate previous findings that adults revise their beliefs about information that is in common ground between interlocutors so that utterances are not redundant with the preexisting beliefs of the listener (CITE).  This revision of beliefs ultimately undermines the literal content of the utterance.  Upon hearing, "My student turned in his homework on time today," for instance, adults will learn that the student turned in his homework on time, but they will also infer that the student must not \emph{typically} turn in his homework on time.



%we developed a computational model that predicts this behavior; 2) we demonstrated that adults do \emph{not} make this inference when the listener's uncertainty about the event is in common ground with the speaker, or when the utterance is removed from a conversational context (i.e., when it is framed as an observation); and 3) we provide evidence that the strength of the backfiring effect systematically varies according to the strength adults' preexisting beliefs. \red{add more explanation here}

In addition to contributing to our knowledge of language understanding, this work has practical relevance.  
Recent efforts to persuade the general public that there is no causal relation between vaccines and autism, for example, include articles titled, "Vaccines do not cause autism" \red{(cite e.g., CDC)}.  
Similarly, websites, media outlets, and researchers tend to state, ``Girls can do math,'' as a way of promoting gender equality \red{(cite e.g., Smithsonian Mag}).  
While these two statements would certainly be useful and informative for those who hold the belief that vaccines \emph{do} cause autism or that girls \emph{cannot} do math, it is unclear how they might be received by people who already share these beliefs, or who are not aware of either of these debates.  
The headline, ``Girls can do math'', for instance, could potentially signal to naive readers that many people believe that girls \emph{cannot} do math, and that there are legitimate reasons to hold this belief (e.g., perhaps girls tend to be less intelligent than boys).  
As a result, these readers might walk away doubting girls' ability to do math more than they would have otherwise.  Understanding how we process potentially uninformative utterances is therefore important not only for developing theories of language, but also for effectively promoting social change.

%In the present study, our focus was on affirmations of past events (e.g., ``My student turned in his homework on time''; ``The gym had clean towels today''), as a first step towards modeling this backfiring effect of language.  
%Further work is necessary to determine how other kinds of affirmations, such as generic claims, might also backfire.



\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{backfiring-cogsci2016}


\end{document}
