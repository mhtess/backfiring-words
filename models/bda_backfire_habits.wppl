// time webppl bda_backfire_habits.wppl --require mht --require utils

var prior_mhiter = 300000
var prior_burn = prior_mhiter/2
var prior_incrOpts = {burn:prior_burn, verbose: true, verboseLag: prior_mhiter/20}
var priorERP = IncrementalMH(priors_3compModel, prior_mhiter, prior_incrOpts)

var d= mht.readCSV(fpath+"propensity-1-trials.csv").data
var df = dataFrame(d.slice(0,d.length-1), ["log_dayrate"])

var priorERPobject = _.object(map(function(i){
	return [i, marginalize(priorERP, i)]
}, items))

var scaleFromDailyRate = {
	"week":7,
	"month":30,
	"year":365,
	"5 years": 365*5
}

var scaleTo5years = {
	"day":365*5,
	"week":52*5,
	"month":12*5,
	"year":5,
	"5 years": 1
}

var scorePoissonLink = function(erp, d){
	return util.logsumexp(map(function(s){
		var logp = erp.score([],s)
		return logp+poissonERP.score([s], d)
	}, erp.support()
	))
}

var normalLink = function(erp, d, data_analytic_sigma){
	return util.logsumexp(map(function(s){
		var logp = erp.score([],s)
		return logp+gaussianERP.score([s, data_analytic_sigma], d)
	}, erp.support()
	))
}

var addGuessingAndScale = function(erp, phi){
	Enumerate(function(){
		var guessing = flip(phi)
		var response = guessing ? 
					uniformDraw([1,5,10,20])*scaleTo5years[uniformDraw(["day","week","month","year","5 years"])] :
					scaleFromDailyRate["5 years"]*sample(erp)
		return response
	})
}

console.log(items)
var posteriorBDA = function(){
	var speaker_optimality = uniform(0,20)

	var data_analytic_sigma = uniform(0,5)
	// var utterance_cost = uniform(0, 10)
	var utterance_cost = 1

	foreach(items, function(i){

		var df_item = subset(df, "past", i)

		var backfire_responses = _.pluck(subset(df_item, "condition","communication"), "log_dayrate") // or logdayprob with normal linking fnc
		// var observation_responses = _.pluck(subset(df_item, "condition","observation"), "logdayprob")
		// var baseline_responses = _.pluck(subset(df_item, "condition","baseline"), "logdayprob")
		// console.log(i + backfire_responses)
		// console.log(baseline_responses)

		var itemPriors = priorERPobject[i]
		var prior_i = sample(itemPriors)
		var habit_prior = discretize3NormalPrior(prior_i)

		// var habit_rate_params = sample(priorERPobject[i]["habit_rate"])
		// var habit_strength_params = sample(priorERPobject[i]["habit_strength"])


		// var habit_rate = beta(habit_rate_params.a,habit_rate_params.b)
		// // var habit_rate = habit_strength_params.theta
		// // console.log(habit_strength_params)
		// var habit_prior = discretizeLogNormal1(
		// 	habit_strength_params.mu,
		// 	habit_strength_params.sigma
		// 	)

		var prior_parameters = {
			habit_prior: habit_prior,
			cost:utterance_cost
		}

		// console.log(habit_rate)
		// console.log(Math.exp(habit_strength_params.mu),
			// Math.exp(habit_strength_params.sigma))
		// console.log('enter rsa')
		var backfireERP = listener1("It happened.", habit_prior,speaker_optimality, utterance_cost)
		// console.log(map(function(s){return [s, Math.exp(backfireERP.score([], s))]}, backfireERP.support()))
		// console.log(backfire_responses)
		// console.log('leave rsa')
		var backfiringScr = sum(map(function(d){
			// var scr = backfireERP.score([], d)
			var scr = normalLink(backfireERP, d, data_analytic_sigma)
			// console.log("d = " + d + "; scr = " + scr)
			return scr
		}, backfire_responses))

		var observationERP = literalBayesian("It happened.",habit_prior)
		// console.log(map(function(s){return [s, Math.exp(observationERP.score([], s))]}, observationERP.support()))

		// var observationScr = sum(map(function(d){
		// 	// console.log("d = " + d)
		// 	var scr = normalLink(observationERP, d, data_analytic_sigma)
		// 	// var scr = observationERP.score([], d)
		// 	return scr
		// }, observation_responses))
		// var observationScr = sum(map(function(d){return observationERP.score([], d)}, observation_responses))
		// console.log("after observation")

		// var baselineERP = literalBayesian("It happened.",prior_parameters)
		// console.log(map(function(s){return [s, Math.exp(baselineERP.score([], s))]}, baselineERP.support()))
		// console.log(baseline_responses)
		// var baselineScr = sum(map(function(d){
		// 	// console.log(d)
		// 	var scr = normalLink(baselineERP, d, data_analytic_sigma)
		// 	// var scr = baselineERP.score([], d)
		// 	return scr
		// }, baseline_responses))
		// // console.log(map(function(s){return [s, Math.exp(baselineERP.score([], s))]}, baselineERP.support()))

		// console.log("backfire score = " +backfiringScr)
		// console.log("observation score = " +observationScr)
		// console.log("baseline score = " +baselineScr)
		factor(backfiringScr)
		// factor(backfiringScr)

		query.add(["predictive_daily","communication", i], expectation(backfireERP))
		query.add(["predictive_daily","observation", i], expectation(observationERP))
		query.add(["predictive_daily","baseline", i], expectation(habit_prior, function(x){return Math.log(x)}))

	})

	query.add(["parameter", "speaker_optimality", "NA"], speaker_optimality)
	query.add(["parameter", "data_analytic_sigma", "NA"], data_analytic_sigma)

	return query
}

var mhiter = 25000
var burn = mhiter/2
var incrOpts = {burn:burn, verbose: true, verboseLag: mhiter/20}
var posteriorERP = IncrementalMH(posteriorBDA, mhiter, incrOpts)
// var posteriorERP = MCMC(posteriorBDA, {samples: burn, burn:burn, verbose: true})

console.log("inference complete --- writing to file")
var outFile = "results/bda-backfire-propensity1-n30-so-normalLink-IncrMH" + 
			mhiter/1000 + "k-b" + burn/1000 + "k" +"_priorMH" + prior_mhiter/1000 + 
				"k-b" + prior_burn/1000 + "kb.csv"
var header = "Type,Condition,Item,Value"

mht.erpWriter(posteriorERP, outFile, header)

console.log("posterior written to " + outFile)